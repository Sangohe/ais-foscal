{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ml_collections\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import importlib\n",
    "from typing import Callable, Optional\n",
    "\n",
    "from models import vanilla\n",
    "from utils import plotting\n",
    "from metrics import compute_segmentation_metrics\n",
    "from utils.datasets.foscal.patient import FOSCALPatient\n",
    "from utils.config import get_path_of_directory_with_id, load_yaml_config\n",
    "from utils.preprocessing.numpy import binarize_array\n",
    "from utils.preprocessing.tensorflow import resize_data, resize_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_method_from_config(\n",
    "    config: ml_collections.ConfigDict, attr: str\n",
    ") -> Optional[Callable]:\n",
    "    \"\"\"Imports a method from a config attribute.\"\"\"\n",
    "    if attr in config:\n",
    "        return import_method(config[attr])\n",
    "\n",
    "def import_method(method_path: str) -> Callable:\n",
    "    \"\"\"Import a method from a module path.\"\"\"\n",
    "    method_shards = method_path.split(\".\")\n",
    "    method_shards[0] = {\n",
    "        \"np\": \"numpy\",\n",
    "        \"tf\": \"tensorflow\",\n",
    "        \"tfa\": \"tensorflow_addons\",\n",
    "    }.get(method_shards[0], method_shards[0])\n",
    "\n",
    "    module_path = \".\".join(method_shards[:-1])\n",
    "    method_name = method_shards[-1]\n",
    "\n",
    "    module = importlib.import_module(module_path)\n",
    "    return getattr(module, method_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dual_unet_on_foscal_dataset(model, config, subdir):\n",
    "    \n",
    "    if subdir is None:\n",
    "        save_dir = config.evaluation_dir\n",
    "    else:\n",
    "        save_dir = os.path.join(config.evaluation_dir, subdir)\n",
    "\n",
    "\n",
    "    input_shape = tuple(int(x) for x in config.model.input_shape.split(\",\"))\n",
    "    modalities = config.dataloader.modalities.split(\",\")\n",
    "\n",
    "    for radiologist in [\"Daniel\", \"Andres\"]:\n",
    "        \n",
    "        valid_dir = os.path.join(save_dir, \"valid\", radiologist)\n",
    "        os.makedirs(valid_dir, exist_ok=True)\n",
    "\n",
    "        metric_names = [\"sens\", \"spec\", \"ppv\", \"npv\", \"dsc\", \"avd\", \"hd\"]\n",
    "        adc_results = {m: [] for m in metric_names}\n",
    "        adc_results[\"patient\"] = []\n",
    "        dwi_results = {m: [] for m in metric_names}\n",
    "        dwi_results[\"patient\"] = []\n",
    "\n",
    "        patient_paths = np.loadtxt(config.dataloader.valid_patients_path, dtype=str)\n",
    "        for patient_path in patient_paths:\n",
    "            patient = FOSCALPatient(str(patient_path))\n",
    "            original_shape = (patient.original_shape[0], patient.original_shape[1])\n",
    "            patient_dir = os.path.join(valid_dir, patient.patient_id)\n",
    "            os.makedirs(patient_dir, exist_ok=True)\n",
    "\n",
    "            data_dict = patient.get_data(modalities, normalization=\"min_max\")\n",
    "            data = {\n",
    "                k: np.expand_dims(v.transpose(2, 0, 1), -1) for k, v in data_dict.items()\n",
    "            }\n",
    "            data = np.concatenate(list(data.values()), axis=-1)\n",
    "            resized_data = resize_data(data, input_shape[:2])\n",
    "            resized_data = (\n",
    "                resized_data[..., 0:1],\n",
    "                resized_data[..., 1:],\n",
    "            )\n",
    "\n",
    "            # Predict the lesion. Keep the last output if the model is deeply supervised.\n",
    "            adc_probabilities, dwi_probabilities = model.predict(resized_data)\n",
    "\n",
    "            adc_pred_mask = binarize_array(adc_probabilities, threshold=0.5)\n",
    "            adc_pred_mask = adc_pred_mask[..., 0].transpose(1, 2, 0)\n",
    "            adc_resized_pred_mask = resize_mask(adc_pred_mask, original_shape).numpy()\n",
    "\n",
    "            dwi_pred_mask = binarize_array(dwi_probabilities, threshold=0.5)\n",
    "            dwi_pred_mask = dwi_pred_mask[..., 0].transpose(1, 2, 0)\n",
    "            dwi_resized_pred_mask = resize_mask(dwi_pred_mask, original_shape).numpy()\n",
    "\n",
    "            # Save each prediction and mask.\n",
    "            niftis_dir = os.path.join(patient_dir, \"niftis\")\n",
    "            os.makedirs(niftis_dir, exist_ok=True)\n",
    "            shutil.copy(getattr(patient, \"adc_daniel_mask_path\"), niftis_dir)\n",
    "            shutil.copy(getattr(patient, \"dwi_daniel_mask_path\"), niftis_dir)\n",
    "\n",
    "            # Compute metrics.\n",
    "            adc_mask = patient.get_mask(modalities=modalities, radiologist=radiologist)[\n",
    "                \"ADC\"\n",
    "            ]\n",
    "            adc_vol_metrics = compute_segmentation_metrics(adc_mask, adc_resized_pred_mask)\n",
    "            adc_results[\"patient\"].append(patient.patient_id)\n",
    "            for m in metric_names:\n",
    "                adc_results[m].append(adc_vol_metrics[m])\n",
    "\n",
    "            # Create the titles and append the arrays for creating plots later.\n",
    "            title = plotting.create_title_with_metrics(**adc_vol_metrics)\n",
    "            overlapped_ots_path = os.path.join(\n",
    "                patient_dir, \"adc_data_and_ots_overlapped.png\"\n",
    "            )\n",
    "            animation_save_path = os.path.join(patient_dir, f\"adc_animation.gif\")\n",
    "            plotting.plot_data_with_overlapping_ots(\n",
    "                data_dict[\"ADC\"],\n",
    "                adc_mask,\n",
    "                adc_resized_pred_mask,\n",
    "                save_path=overlapped_ots_path,\n",
    "                show_plot=False,\n",
    "                title=title,\n",
    "            )\n",
    "            plotting.save_animated_data_with_overlapping_ots(\n",
    "                data_dict[\"ADC\"],\n",
    "                adc_mask,\n",
    "                adc_resized_pred_mask,\n",
    "                save_path=animation_save_path,\n",
    "                titles=title,\n",
    "            )\n",
    "\n",
    "            dwi_mask = patient.get_mask(modalities=modalities, radiologist=radiologist)[\n",
    "                \"DWI\"\n",
    "            ]\n",
    "            dwi_vol_metrics = compute_segmentation_metrics(dwi_mask, dwi_resized_pred_mask)\n",
    "            dwi_results[\"patient\"].append(patient.patient_id)\n",
    "            for m in metric_names:\n",
    "                dwi_results[m].append(dwi_vol_metrics[m])\n",
    "\n",
    "            # Create the titles and append the arrays for creating plots later.\n",
    "            title = plotting.create_title_with_metrics(**dwi_vol_metrics)\n",
    "            overlapped_ots_path = os.path.join(\n",
    "                patient_dir, \"dwi_data_and_ots_overlapped.png\"\n",
    "            )\n",
    "            animation_save_path = os.path.join(patient_dir, f\"dwi_animation.gif\")\n",
    "            plotting.plot_data_with_overlapping_ots(\n",
    "                data_dict[\"DWI\"],\n",
    "                dwi_mask,\n",
    "                dwi_resized_pred_mask,\n",
    "                save_path=overlapped_ots_path,\n",
    "                show_plot=False,\n",
    "                title=title,\n",
    "            )\n",
    "            plotting.save_animated_data_with_overlapping_ots(\n",
    "                data_dict[\"DWI\"],\n",
    "                dwi_mask,\n",
    "                dwi_resized_pred_mask,\n",
    "                save_path=animation_save_path,\n",
    "                titles=title,\n",
    "            )\n",
    "\n",
    "        if len(adc_results[\"patient\"]) != 0:\n",
    "            metrics_per_patient = pd.DataFrame(adc_results)\n",
    "            metrics_per_patient = metrics_per_patient.set_index(\"patient\")\n",
    "            metrics_per_patient.loc[\"mean\"] = metrics_per_patient.mean()\n",
    "            metrics_per_patient.loc[\"std\"] = metrics_per_patient.std()\n",
    "            metrics_per_patient.to_csv(os.path.join(valid_dir, \"adc_patient_metrics.csv\"))\n",
    "\n",
    "        if len(dwi_results[\"patient\"]) != 0:\n",
    "            metrics_per_patient = pd.DataFrame(dwi_results)\n",
    "            metrics_per_patient = metrics_per_patient.set_index(\"patient\")\n",
    "            metrics_per_patient.loc[\"mean\"] = metrics_per_patient.mean()\n",
    "            metrics_per_patient.loc[\"std\"] = metrics_per_patient.std()\n",
    "            metrics_per_patient.to_csv(os.path.join(valid_dir, \"dwi_patient_metrics.csv\"))\n",
    "\n",
    "def evaluate_unet_on_foscal_dataset(model, config, subdir):\n",
    "    \n",
    "    if subdir is None:\n",
    "        save_dir = config.evaluation_dir\n",
    "    else:\n",
    "        save_dir = os.path.join(config.evaluation_dir, subdir)\n",
    "\n",
    "\n",
    "    input_shape = tuple(int(x) for x in config.model.input_shape.split(\",\"))\n",
    "    modalities = config.dataloader.modalities.split(\",\")\n",
    "\n",
    "    for radiologist in [\"Daniel\", \"Andres\"]:\n",
    "        \n",
    "        valid_dir = os.path.join(save_dir, \"valid\", radiologist)\n",
    "        os.makedirs(valid_dir, exist_ok=True)\n",
    "\n",
    "        metric_names = [\"sens\", \"spec\", \"ppv\", \"npv\", \"dsc\", \"avd\", \"hd\"]\n",
    "        results = {m: [] for m in metric_names}\n",
    "        results[\"patient\"] = []\n",
    "        patient_paths = np.loadtxt(config.dataloader.valid_patients_path, dtype=str)\n",
    "        for patient_path in patient_paths:\n",
    "            patient = FOSCALPatient(str(patient_path))\n",
    "            original_shape = (patient.original_shape[0], patient.original_shape[1])\n",
    "            patient_dir = os.path.join(valid_dir, patient.patient_id)\n",
    "            os.makedirs(patient_dir, exist_ok=True)\n",
    "\n",
    "            data_dict = patient.get_data(modalities, normalization=\"min_max\")\n",
    "            data = {\n",
    "                k: np.expand_dims(v.transpose(2, 0, 1), -1) for k, v in data_dict.items()\n",
    "            }\n",
    "            data = np.concatenate(list(data.values()), axis=-1)\n",
    "            resized_data = resize_data(data, input_shape[:2])\n",
    "\n",
    "            # Predict the lesion. Keep the last output if the model is deeply supervised.\n",
    "            probabilities = model.predict(resized_data)\n",
    "            if isinstance(probabilities, (list, tuple)):\n",
    "                probabilities = probabilities[-1]\n",
    "            pred_mask = binarize_array(probabilities, threshold=0.5)\n",
    "            pred_mask = pred_mask[..., 0].transpose(1, 2, 0)\n",
    "            resized_pred_mask = resize_mask(pred_mask, original_shape).numpy()\n",
    "\n",
    "            # Save each prediction and mask.\n",
    "            niftis_dir = os.path.join(patient_dir, \"niftis\")\n",
    "            os.makedirs(niftis_dir, exist_ok=True)\n",
    "\n",
    "            mask_attr = modalities[0].lower()\n",
    "            if hasattr(patient, mask_attr):\n",
    "                shutil.copy(getattr(patient, mask_attr + \"_path\"), niftis_dir)\n",
    "\n",
    "                # Compute metrics.\n",
    "                mask = patient.get_mask(modalities=modalities, radiologist=radiologist)[\n",
    "                    modalities[0]\n",
    "                ]\n",
    "                vol_metrics = compute_segmentation_metrics(mask, resized_pred_mask)\n",
    "                results[\"patient\"].append(patient.patient_id)\n",
    "                for m in metric_names:\n",
    "                    results[m].append(vol_metrics[m])\n",
    "\n",
    "                # Create the titles and append the arrays for creating plots later.\n",
    "                title = plotting.create_title_with_metrics(**vol_metrics)\n",
    "                key_list = list(data_dict.keys())\n",
    "                first_key = key_list[0]\n",
    "\n",
    "                overlapped_ots_path = os.path.join(\n",
    "                    patient_dir, \"data_and_ots_overlapped.png\"\n",
    "                )\n",
    "                animation_save_path = os.path.join(patient_dir, f\"animation.gif\")\n",
    "\n",
    "                plotting.plot_data_with_overlapping_ots(\n",
    "                    data_dict[first_key],\n",
    "                    mask,\n",
    "                    resized_pred_mask,\n",
    "                    save_path=overlapped_ots_path,\n",
    "                    show_plot=False,\n",
    "                    title=title,\n",
    "                )\n",
    "\n",
    "                plotting.save_animated_data_with_overlapping_ots(\n",
    "                    data_dict[first_key],\n",
    "                    mask,\n",
    "                    resized_pred_mask,\n",
    "                    save_path=animation_save_path,\n",
    "                    titles=title,\n",
    "                )\n",
    "\n",
    "        if len(results[\"patient\"]) != 0:\n",
    "            metrics_per_patient = pd.DataFrame(results)\n",
    "            metrics_per_patient = metrics_per_patient.set_index(\"patient\")\n",
    "            metrics_per_patient.loc[\"mean\"] = metrics_per_patient.mean()\n",
    "            metrics_per_patient.loc[\"std\"] = metrics_per_patient.std()\n",
    "            metrics_per_patient.to_csv(os.path.join(valid_dir, \"patient_metrics.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_experiment_best_model(experiment_id):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    experiment_dir = get_path_of_directory_with_id(experiment_id)\n",
    "\n",
    "    # Load config files.\n",
    "    config = load_yaml_config(os.path.join(experiment_dir, \"config\", \"config.yml\"))\n",
    "    config = ml_collections.ConfigDict(config)\n",
    "\n",
    "    # Create the model and load the best weights.\n",
    "    model_config = config.model.to_dict()\n",
    "    model_config[\"input_shape\"] = tuple(int(s) for s in config.model.input_shape.split(\",\"))\n",
    "    model_config[\"filters_per_level\"] = [int(f) for f in config.model.filters_per_level.split(\",\")]\n",
    "    model_config[\"blocks_depth\"] = [int(f) for f in config.model.blocks_depth.split(\",\")]\n",
    "    model_config[\"norm_layer\"] = import_method_from_config(config.model, \"norm_layer\")\n",
    "    model_config[\"upsample_layer\"] = import_method_from_config(config.model, \"upsample_layer\")\n",
    "    model_config[\"attention_layer\"] = import_method_from_config(config.model, \"attention_layer\")\n",
    "    model_config[\"pooling_layer\"] = import_method_from_config(config.model, \"pooling_layer\")\n",
    "\n",
    "    # Iterate over the test patients and compute the metrics for both radiologists.\n",
    "    if experiment_id > 9:\n",
    "        model = vanilla.DualUnet(**model_config)\n",
    "        model.load_weights(config.best_weights_path).expect_partial()\n",
    "        evaluate_dual_unet_on_foscal_dataset(model, config, \"best\")\n",
    "    else:\n",
    "        encoder = vanilla.UNetEncoder(**model_config)\n",
    "        skip_names = vanilla.get_skip_names_from_encoder(encoder)\n",
    "        model = vanilla.UNet(encoder, skip_names, **model_config)\n",
    "        hidden_layer_names = vanilla.get_output_names_for_deep_supervision(model)\n",
    "        model = vanilla.add_deep_supervision_to_unet(model, hidden_layer_names)\n",
    "        model.load_weights(config.best_weights_path).expect_partial()\n",
    "        evaluate_unet_on_foscal_dataset(model, config, \"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the baseline UNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [16:43<00:00, 100.40s/it]\n"
     ]
    }
   ],
   "source": [
    "for experiment_id in tqdm(range(10)):\n",
    "    evaluate_experiment_best_model(experiment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the Dual UNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [16:02<00:00, 192.54s/it]\n"
     ]
    }
   ],
   "source": [
    "for experiment_id in tqdm(range(10, 15)):\n",
    "    evaluate_experiment_best_model(experiment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict for figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dual_predict_on_foscal_patients(model, config, patient_paths, experiment_id):\n",
    "    input_shape = tuple(int(x) for x in config.model.input_shape.split(\",\"))\n",
    "    modalities = config.dataloader.modalities.split(\",\")\n",
    "        \n",
    "    for patient_path in patient_paths:\n",
    "        patient_dir = os.path.join(\"figs\", \"results\", f\"{experiment_id}\", os.path.basename(patient_path))\n",
    "        os.makedirs(patient_dir, exist_ok=True)\n",
    "\n",
    "        patient = FOSCALPatient(str(patient_path))\n",
    "        original_shape = (patient.original_shape[0], patient.original_shape[1])\n",
    "\n",
    "        data_dict = patient.get_data(modalities, normalization=\"min_max\")\n",
    "        data = {\n",
    "            k: np.expand_dims(v.transpose(2, 0, 1), -1) for k, v in data_dict.items()\n",
    "        }\n",
    "        data = np.concatenate(list(data.values()), axis=-1)\n",
    "        resized_data = resize_data(data, input_shape[:2])\n",
    "        resized_data = (\n",
    "            resized_data[..., 0:1],\n",
    "            resized_data[..., 1:],\n",
    "        )\n",
    "\n",
    "        # Predict the lesion. Keep the last output if the model is deeply supervised.\n",
    "        adc_probabilities, dwi_probabilities = model.predict(resized_data)\n",
    "\n",
    "        adc_pred_mask = binarize_array(adc_probabilities, threshold=0.5)\n",
    "        adc_pred_mask = adc_pred_mask[..., 0].transpose(1, 2, 0)\n",
    "        adc_resized_pred_mask = resize_mask(adc_pred_mask, original_shape).numpy()\n",
    "\n",
    "        dwi_pred_mask = binarize_array(dwi_probabilities, threshold=0.5)\n",
    "        dwi_pred_mask = dwi_pred_mask[..., 0].transpose(1, 2, 0)\n",
    "        dwi_resized_pred_mask = resize_mask(dwi_pred_mask, original_shape).numpy()\n",
    "\n",
    "        # Get the annotations for each radiologist.\n",
    "        daniel_masks = patient.get_mask(modalities=modalities, radiologist=\"Daniel\")\n",
    "        andres_masks = patient.get_mask(modalities=modalities, radiologist=\"Andres\")\n",
    "        daniel_adc_mask, daniel_dwi_mask = daniel_masks[\"ADC\"], daniel_masks[\"DWI\"]\n",
    "        andres_adc_mask, andres_dwi_mask = andres_masks[\"ADC\"], andres_masks[\"DWI\"]\n",
    "\n",
    "        # Save resources as npy.\n",
    "        np.save(os.path.join(patient_dir, \"adc.npy\"), data[..., 0].transpose(1, 2, 0))\n",
    "        np.save(os.path.join(patient_dir, \"adc_daniel_mask.npy\"), daniel_adc_mask)\n",
    "        np.save(os.path.join(patient_dir, \"adc_andres_mask.npy\"), andres_adc_mask)\n",
    "        np.save(os.path.join(patient_dir, \"adc_resized_pred_mask.npy\"), adc_resized_pred_mask)\n",
    "        np.save(os.path.join(patient_dir, \"dwi.npy\"), data[..., 1].transpose(1, 2, 0))\n",
    "        np.save(os.path.join(patient_dir, \"dwi_daniel_mask.npy\"), daniel_dwi_mask)\n",
    "        np.save(os.path.join(patient_dir, \"dwi_andres_mask.npy\"), andres_dwi_mask)\n",
    "        np.save(os.path.join(patient_dir, \"dwi_resized_pred_mask.npy\"), dwi_resized_pred_mask)\n",
    "\n",
    "def predict_on_foscal_patients(model, config, patient_paths, experiment_id):\n",
    "    input_shape = tuple(int(x) for x in config.model.input_shape.split(\",\"))\n",
    "    modalities = config.dataloader.modalities.split(\",\")\n",
    "    assert len(modalities) == 1\n",
    "        \n",
    "    for patient_path in patient_paths:\n",
    "        patient_dir = os.path.join(\"figs\", \"results\", f\"{experiment_id}\", os.path.basename(patient_path))\n",
    "        os.makedirs(patient_dir, exist_ok=True)\n",
    "\n",
    "        patient = FOSCALPatient(str(patient_path))\n",
    "        original_shape = (patient.original_shape[0], patient.original_shape[1])\n",
    "\n",
    "        data_dict = patient.get_data(modalities, normalization=\"min_max\")\n",
    "        data = {\n",
    "            k: np.expand_dims(v.transpose(2, 0, 1), -1) for k, v in data_dict.items()\n",
    "        }\n",
    "        data = np.concatenate(list(data.values()), axis=-1)\n",
    "        resized_data = resize_data(data, input_shape[:2])\n",
    "\n",
    "        # Predict the lesion. Keep the last output if the model is deeply supervised.\n",
    "        probabilities = model.predict(resized_data)\n",
    "        if isinstance(probabilities, (list, tuple)):\n",
    "            probabilities = probabilities[-1]\n",
    "        pred_mask = binarize_array(probabilities, threshold=0.5)\n",
    "        pred_mask = pred_mask[..., 0].transpose(1, 2, 0)\n",
    "        resized_pred_mask = resize_mask(pred_mask, original_shape).numpy()\n",
    "\n",
    "        # Get the annotations for each radiologist.\n",
    "        modality = modalities[0]\n",
    "        daniel_masks = patient.get_mask(modalities=modalities, radiologist=\"Daniel\")\n",
    "        andres_masks = patient.get_mask(modalities=modalities, radiologist=\"Andres\")\n",
    "        daniel_mask = daniel_masks[modality]\n",
    "        andres_mask = andres_masks[modality]\n",
    "\n",
    "        # Save resources as npy.\n",
    "        np.save(os.path.join(patient_dir, f\"{modality.lower()}.npy\"), data[..., 0].transpose(1, 2, 0))\n",
    "        np.save(os.path.join(patient_dir, f\"{modality.lower()}_daniel_mask.npy\"), daniel_mask)\n",
    "        np.save(os.path.join(patient_dir, f\"{modality.lower()}_andres_mask.npy\"), andres_mask)\n",
    "        np.save(os.path.join(patient_dir, f\"{modality.lower()}_resized_pred_mask.npy\"), resized_pred_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paciente 021, 034, experimento 13 (fold 4)\n",
    "def dual_predict_for_experiment(experiment_id, patient_paths):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    experiment_dir = get_path_of_directory_with_id(experiment_id)\n",
    "\n",
    "    # Load config files.\n",
    "    config = load_yaml_config(os.path.join(experiment_dir, \"config\", \"config.yml\"))\n",
    "    config = ml_collections.ConfigDict(config)\n",
    "\n",
    "    # Create the model and load the best weights.\n",
    "    model_config = config.model.to_dict()\n",
    "    model_config[\"input_shape\"] = tuple(int(s) for s in config.model.input_shape.split(\",\"))\n",
    "    model_config[\"filters_per_level\"] = [int(f) for f in config.model.filters_per_level.split(\",\")]\n",
    "    model_config[\"blocks_depth\"] = [int(f) for f in config.model.blocks_depth.split(\",\")]\n",
    "    model_config[\"norm_layer\"] = import_method_from_config(config.model, \"norm_layer\")\n",
    "    model_config[\"upsample_layer\"] = import_method_from_config(config.model, \"upsample_layer\")\n",
    "    model_config[\"attention_layer\"] = import_method_from_config(config.model, \"attention_layer\")\n",
    "    model_config[\"pooling_layer\"] = import_method_from_config(config.model, \"pooling_layer\")\n",
    "\n",
    "    # Iterate over the test patients and compute the metrics for both radiologists.\n",
    "    if experiment_id > 9:\n",
    "        model = vanilla.DualUnet(**model_config)\n",
    "        model.load_weights(config.best_weights_path).expect_partial()\n",
    "        dual_predict_on_foscal_patients(model, config, patient_paths, experiment_id)\n",
    "    else:\n",
    "        encoder = vanilla.UNetEncoder(**model_config)\n",
    "        skip_names = vanilla.get_skip_names_from_encoder(encoder)\n",
    "        model = vanilla.UNet(encoder, skip_names, **model_config)\n",
    "        hidden_layer_names = vanilla.get_output_names_for_deep_supervision(model)\n",
    "        model = vanilla.add_deep_supervision_to_unet(model, hidden_layer_names)\n",
    "        model.load_weights(config.best_weights_path).expect_partial()\n",
    "        predict_on_foscal_patients(model, config, patient_paths, experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_paths = [\n",
    "    \"/data/Datasets/stroke/ISBI_FOSCAL/ACV-034\", \n",
    "    \"/data/Datasets/stroke/ISBI_FOSCAL/ACV-021\", \n",
    "    \"/data/Datasets/stroke/ISBI_FOSCAL/ACV-031\"\n",
    "]\n",
    "\n",
    "for experiment_id in tqdm([6, 7, 13]):\n",
    "    dual_predict_for_experiment(experiment_id, patient_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
